# perception-voice configuration
# Copy this file to config.yml before running the server.
# All fields are required.

server:
  # Unix domain socket path (relative to workspace root, or absolute path)
  socket_path: "perception.sock"

  # How long to retain transcriptions in memory (minutes)
  buffer_retention_minutes: 30

  # Phrases to discard (Whisper hallucinates these from coughs/sneezes)
  # Matching is case-insensitive and alphanumeric-only
  discard_phrases:
    - "thank you"
    - "thanks"
    - "you"

audio:
  # Sample rate for audio capture (Hz)
  sample_rate: 16000

  # Audio buffer size (samples per chunk)
  # Silero VAD requires at least 512 samples
  buffer_size: 512

  # Microphone device index (null for auto-detect)
  mic_device: null

  # Minimum duration of speech to transcribe (seconds)
  min_utterance_duration: 1.1

  # Silence duration before finalizing transcription (seconds)
  post_speech_silence_duration: 0.6

  # Buffer duration before speech detection (seconds)
  pre_recording_buffer_duration: 1.0

transcription:
  # Model for transcription (downloaded automatically on first startup)
  # Options: tiny, tiny.en, base, base.en, small, small.en, medium, medium.en, large-v2, large-v3
  model: "large-v3"

  # Compute device: "cpu" or "cuda" (for GPU acceleration)
  device: "cuda"

  # Compute type: "int8" (CPU), "float16" (GPU recommended), "float32"
  compute_type: "float16"

  # Language code (e.g., "en", "es", "fr", "de", "zh")
  # Optional: When not set, faster-whisper will autodetect, allowing multiple languages to be spoken.
  language: "en"

  # Beam size for transcription (higher = more accurate, slower)
  beam_size: 5

vad:
  # WebRTC sensitivity (0-3, higher = less sensitive to noise)
  webrtc_sensitivity: 3

  # Silero sensitivity (0.0-1.0, lower = more sensitive)
  silero_sensitivity: 0.05

  # Use ONNX for faster Silero inference on CPU
  silero_use_onnx: true
